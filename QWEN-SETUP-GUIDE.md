# Przewodnik zmiany modelu na Qwen 2.5:7b

## âœ… Co zostaÅ‚o zrobione automatycznie

1. **Zaktualizowano [src/config.js](src/config.js)**
   ```javascript
   ollamaModel: process.env.OLLAMA_MODEL || "qwen2.5:7b"
   ```

2. **Zaktualizowano [.env.example](.env.example)**
   ```bash
   OLLAMA_MODEL=qwen2.5:7b
   ```

3. **Utworzono plik [.env](.env)**
   - Skopiowano z `.env.example` z nowym modelem

4. **Utworzono skrypt [download-qwen.sh](download-qwen.sh)**
   - Automatyczne pobieranie modelu Qwen 2.5:7b

## ğŸ“‹ Co musisz zrobiÄ‡ teraz

### Krok 1: Pobierz model Qwen 2.5:7b

Wybierz jednÄ… z metod:

#### Metoda A: UÅ¼yj gotowego skryptu (zalecane)
```bash
./download-qwen.sh
```

#### Metoda B: RÄ™cznie przez Ollama CLI
```bash
ollama pull qwen2.5:7b
```

#### Metoda C: Przez Docker (jeÅ›li uÅ¼ywasz Docker Compose)
```bash
docker exec -it <ollama-container-name> ollama pull qwen2.5:7b
```

### Krok 2: SprawdÅº czy model zostaÅ‚ pobrany
```bash
ollama list
```

PowinieneÅ› zobaczyÄ‡:
```
NAME            ID              SIZE      MODIFIED
qwen2.5:7b      abc123...       4.7 GB    X minutes ago
llama3.2:3b     def456...       2.0 GB    X days ago
...
```

### Krok 3: Uruchom aplikacjÄ™
```bash
npm start
# lub
node src/cli.js
# lub
docker-compose up
```

## ğŸ“Š Informacje o modelu Qwen 2.5:7b

### Specyfikacja
- **Rozmiar**: ~4.7 GB
- **Parametry**: 7 miliardÃ³w
- **Kwantyzacja**: Q4_K_M (domyÅ›lnie)
- **Rodzina**: Qwen 2.5
- **Kontekst**: 32K tokenÃ³w

### Wymagania systemowe
- **RAM**: minimum 8 GB (zalecane 16 GB)
- **Wolne miejsce**: ~5 GB na dysku
- **GPU**: opcjonalne (NVIDIA z CUDA lub AMD z ROCm)

### Zalety Qwen 2.5:7b vs Llama 3.2:3b

| Funkcja | Llama 3.2:3b | Qwen 2.5:7b |
|---------|--------------|-------------|
| Parametry | 3.2B | 7B |
| JakoÅ›Ä‡ tekstu | Dobra | Bardzo dobra |
| Rozumienie polskiego | Åšrednie | Bardzo dobre |
| SzybkoÅ›Ä‡ | Szybki | Åšredni |
| Rozmiar | 2 GB | 4.7 GB |
| **Polecane dla** | Testy, szybkie iteracje | Produkcja, najlepsza jakoÅ›Ä‡ |

### WydajnoÅ›Ä‡ dla naszych agentÃ³w

Qwen 2.5:7b jest **szczegÃ³lnie dobry** w:
- âœ… Generowaniu dÅ‚ugich, spÃ³jnych tekstÃ³w (referencje)
- âœ… Rozumieniu kontekstu i instrukcji w jÄ™zyku polskim
- âœ… Przestrzeganiu formatÃ³w JSON
- âœ… Poprawnej odmianie przez przypadki i rodzaje
- âœ… Zachowaniu profesjonalnego tonu

## ğŸ”§ Troubleshooting

### Problem: "Model not found"
```bash
# SprawdÅº czy Ollama dziaÅ‚a
curl http://localhost:11434/api/tags

# JeÅ›li nie dziaÅ‚a, uruchom Ollama
ollama serve
```

### Problem: "Out of memory"
ZmieÅ„ na mniejszy wariant:
```bash
# W .env lub config.js zmieÅ„ na:
OLLAMA_MODEL=qwen2.5:3b  # tylko 2GB RAM
```

### Problem: Zbyt wolne generowanie
Opcje:
1. UÅ¼yj GPU jeÅ›li dostÄ™pne
2. Zmniejsz rozmiar modelu na `qwen2.5:3b`
3. ZwiÄ™ksz RAM systemu

### Problem: Model nie odpowiada po polsku
Upewnij siÄ™ Å¼e:
1. UÅ¼ywasz najnowszej wersji Ollama (`ollama --version`)
2. Model zostaÅ‚ w peÅ‚ni pobrany (`ollama list`)
3. Prompty w agentach sÄ… po polsku (sprawdÅº [src/agents.js](src/agents.js))

## ğŸ¯ Testowanie nowego modelu

### Test 1: SprawdÅº podstawowe dziaÅ‚anie
```bash
ollama run qwen2.5:7b "Napisz krÃ³tkie powitanie po polsku"
```

### Test 2: Test systemu agentÃ³w
```bash
node test-agents-system.js
```

### Test 3: Wygeneruj przykÅ‚adowy dokument
UÅ¼yj aplikacji do wygenerowania testowego dokumentu i sprawdÅº jakoÅ›Ä‡.

## ğŸ“ CofniÄ™cie zmian

JeÅ›li chcesz wrÃ³ciÄ‡ do Llama 3.2:3b:

### Metoda 1: ZmieÅ„ zmiennÄ… Å›rodowiskowÄ…
```bash
# W pliku .env
OLLAMA_MODEL=llama3.2:3b
```

### Metoda 2: ZmieÅ„ w konfiguracji
Edytuj [src/config.js](src/config.js):
```javascript
ollamaModel: process.env.OLLAMA_MODEL || "llama3.2:3b"
```

## ğŸš€ Inne warianty Qwen 2.5

JeÅ›li chcesz sprÃ³bowaÄ‡ innych rozmiarÃ³w:

```bash
# Mniejszy, szybszy (2GB)
ollama pull qwen2.5:3b
OLLAMA_MODEL=qwen2.5:3b

# WiÄ™kszy, lepsza jakoÅ›Ä‡ (9GB)
ollama pull qwen2.5:14b
OLLAMA_MODEL=qwen2.5:14b

# NajwiÄ™kszy, najlepsza jakoÅ›Ä‡ (20GB)
ollama pull qwen2.5:32b
OLLAMA_MODEL=qwen2.5:32b

# Specjalistyczny dla kodu
ollama pull qwen2.5-coder:7b
OLLAMA_MODEL=qwen2.5-coder:7b
```

## ğŸ“š Dodatkowe informacje

- **Dokumentacja Qwen**: https://qwenlm.github.io/
- **Ollama dokumentacja**: https://ollama.ai/library/qwen2.5
- **Model card**: https://huggingface.co/Qwen/Qwen2.5-7B

## âœ¨ Podsumowanie

Po wykonaniu krokÃ³w 1-3, twoja aplikacja bÄ™dzie uÅ¼ywaÄ‡ modelu **Qwen 2.5:7b**, ktÃ³ry zapewni:
- LepszÄ… jakoÅ›Ä‡ generowanych dokumentÃ³w
- Lepsze rozumienie jÄ™zyka polskiego
- Bardziej spÃ³jne i profesjonalne teksty
- Lepsze przestrzeganie formatÃ³w i zasad agentÃ³w

Wszystkie agenty AI (Referencje, ZaÅ›wiadczenia, Praktyki) bÄ™dÄ… dziaÅ‚aÄ‡ z nowym modelem bez Å¼adnych dodatkowych zmian w kodzie!
